{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Poisson Regression Examples\"\n",
        "author: \"Hanhua Zhu\"\n",
        "date:  May 7th, 2025\n",
        "callout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n",
        "---\n",
        "\n",
        "\n",
        "## Blueprinty Case Study\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty's software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty's software and after using it. Unfortunately, such data is not available. \n",
        "\n",
        "However, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm's number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty's software. The marketing team would like to use this data to make the claim that firms using Blueprinty's software are more successful in getting their patent applications approved.\n",
        "\n",
        "\n",
        "### Data\n",
        "\n",
        "We begin by loading the dataset containing information on engineering firms and their patenting activity. This includes whether or not a firm uses Blueprinty's software."
      ],
      "id": "698347d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "df.head()"
      ],
      "id": "71e052ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first few rows of the dataset show each firm's number of patents, regional location, age, and whether they are a Blueprinty customer. We see a mix of customer (`iscustomer = 1`) and non-customer firms, with patent counts ranging from 0 to 4. Firm ages vary from around 24 to 38 years, and regions span categories like Midwest and Southwest. These observations suggest the data is well-structured for count-based modeling and that customer status, region, and firm age may all influence patenting outcomes.\n",
        "\n",
        "## Histogram and Mean Comparison by Customer Status\n",
        "\n",
        "We begin by comparing the distribution and average number of patents between firms that use Blueprinty's software and those that do not."
      ],
      "id": "95ab4261"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: fig-styled-hist-hue\n",
        "#| fig-cap: Distribution of Number of Patents by Customer Status\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "# Create a column with label\n",
        "df['customer_status'] = df['iscustomer'].map({0: \"Non-Customer\", 1: \"Customer\"})\n",
        "\n",
        "# Set style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot histogram using seaborn with hue\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df, x=\"patents\", hue=\"customer_status\", bins=20, multiple=\"dodge\", palette=[\"#1f77b4\", \"#ff7f0e\"])\n",
        "plt.xlabel(\"Number of Patents\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Number of Patents by Customer Status\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-styled-hist-hue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics of Patent Counts by Customer Status"
      ],
      "id": "213c62c6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: tbl-patents-summary\n",
        "#| tbl-cap: Summary Statistics of Patents by Customer Status\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "\n",
        "# Create a label column\n",
        "df['customer_status'] = df['iscustomer'].map({0: \"Non-Customer\", 1: \"Customer\"})\n",
        "\n",
        "# Group by customer status and compute summary statistics\n",
        "summary_stats = df.groupby('customer_status')[\"patents\"].agg(['mean', 'std', 'count']).round(6)\n",
        "summary_stats"
      ],
      "id": "tbl-patents-summary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Key Findings: Patent Counts by Customer Status\n",
        "\n",
        "* **Blueprinty customers** had a higher average number of patents (**4.13**) compared to **non-customers** (**3.47**), based on the summary statistics.\n",
        "* The **distribution** of patent counts (see histogram) shows that customers are more likely to have **larger patent portfolios**, with a noticeable **rightward skew** relative to non-customers.\n",
        "* This pattern suggests a potential **positive association** between using Blueprinty’s software and increased patent productivity.\n",
        "* **However**, this is only a **descriptive comparison**. Differences may be due to other firm characteristics such as **region** or **age**. Further **causal modeling** (e.g., regression analysis or matching) is needed to determine whether the use of Blueprinty’s software actually drives higher patent output.\n",
        "\n",
        "\n",
        "Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n",
        "\n",
        "## Comparison of Regions and Ages by Customer Status"
      ],
      "id": "675fc5c9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: fig-region-by-customer\n",
        "#| fig-cap: Distribution of Firms by Region and Customer Status\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "df['customer_status'] = df['iscustomer'].map({0: 'Non-Customer', 1: 'Customer'})\n",
        "\n",
        "# Plot region distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x=\"region\", hue=\"customer_status\", palette=[\"#1f77b4\", \"#ff7f0e\"])\n",
        "plt.title(\"Distribution of Firms by Region and Customer Status\")\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-region-by-customer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: fig-age-by-customer\n",
        "#| fig-cap: Distribution of Firm Age by Customer Status\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "# Boxplot for age by customer status\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(data=df, x=\"customer_status\", y=\"age\", palette=[\"#1f77b4\", \"#ff7f0e\"])\n",
        "plt.title(\"Distribution of Firm Age by Customer Status\")\n",
        "plt.xlabel(\"Customer Status\")\n",
        "plt.ylabel(\"Firm Age (Years)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-age-by-customer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---"
      ],
      "id": "95a77e41"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "• Regional Differences:\n",
        "The bar chart comparing customer status by region (Figure @fig-region-by-customer) shows substantial variation in software adoption across regions. For example, the Northeast has a notably higher number of Blueprinty customers compared to non-customers, while regions like the Midwest and Southwest are dominated by non-customers. This suggests that geographic location may influence adoption—potentially due to industry concentration, marketing reach, or regional innovation ecosystems.\n",
        "\n",
        "• Age Differences:\n",
        "The boxplot in Figure @fig-age-by-customer indicates that customer firms tend to be slightly older than non-customers. While the median age is only modestly higher for customers, the distribution shows a broader spread and slightly higher upper quartiles, suggesting some older firms are more likely to adopt the software.\n",
        "\n",
        "• Conclusion:\n",
        "These findings imply that both region and firm age may confound the observed relationship between customer status and patent output. Any further analysis aiming to assess the impact of Blueprinty’s software should control for these variables to avoid biased conclusions.\n",
        "\n",
        "### Estimation of Simple Poisson Model\n",
        "\n",
        "Since our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n",
        "\n",
        "\n",
        "### Estimation of Simple Poisson Model\n",
        "\n",
        "We assume the number of patents per firm, $Y_i$, follows a Poisson distribution: $Y_i \\sim \\text{Poisson}(\\lambda)$. The probability mass function is:\n",
        "\n",
        "$$\n",
        "f(Y_i | \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n",
        "$$\n",
        "\n",
        "The log-likelihood for $n$ observations is:\n",
        "\n",
        "$$\n",
        "\\log \\mathcal{L}(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n",
        "$$\n",
        "\n",
        "We compute this value below for a given $\\lambda$."
      ],
      "id": "fa891766"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: poisson-loglik\n",
        "#| echo: true\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import gammaln\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "y = df[\"patents\"]\n",
        "\n",
        "def poisson_log_likelihood(y, lamb):\n",
        "    n = len(y)\n",
        "    return -n * lamb + y.sum() * np.log(lamb) - gammaln(y + 1).sum()\n",
        "\n",
        "lambda_val = 3.5\n",
        "loglik = poisson_log_likelihood(y, lambda_val)\n",
        "print(f\"Poisson log-likelihood at lambda = {lambda_val}: {loglik:.4f}\")"
      ],
      "id": "poisson-loglik",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation of Poisson Log-Likelihood\n",
        "\n",
        "The Poisson log-likelihood evaluated at $\\lambda = 3.5$ is:\n",
        "\n",
        "```\n",
        "Poisson log-likelihood at lambda = 3.5: −3374.8661\n",
        "```\n",
        "\n",
        "This value is **higher (less negative)** than the log-likelihood computed at $\\lambda = 4.0$, which was approximately −3386.84. Therefore, a rate parameter of $\\lambda = 3.5$ provides a **better fit** to the observed patent count data under the Poisson model.\n",
        "\n",
        "> **Note**: This is still a trial value. To find the best-fitting $\\lambda$, we must identify the value that **maximizes** the log-likelihood function. In the next step, we estimate the **Maximum Likelihood Estimator (MLE)** numerically.\n",
        "\n",
        "\n",
        "\n",
        "### Poisson Log-Likelihood Curve for Different Values of $\\lambda$"
      ],
      "id": "87042629"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-poisson-loglik-curve\n",
        "#| fig-cap: Poisson Log-Likelihood as a Function of λ\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import gammaln\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "Y = df[\"patents\"]\n",
        "def poisson_log_likelihood(Y, lambda_):\n",
        "    Y = np.asarray(Y)\n",
        "    n = len(Y)\n",
        "    return -n * lambda_ + Y.sum() * np.log(lambda_) - gammaln(Y + 1).sum()\n",
        "lambda_vals = np.linspace(1.0, 6.0, 100)\n",
        "loglik_vals = [poisson_log_likelihood(Y, l) for l in lambda_vals]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(lambda_vals, loglik_vals, color='blue')\n",
        "plt.axvline(x=Y.mean(), color='red', linestyle='--', label=f'Mean(Y) ≈ {Y.mean():.2f}')\n",
        "plt.xlabel(\"λ (Lambda)\")\n",
        "plt.ylabel(\"Log-Likelihood\")\n",
        "plt.title(\"Poisson Log-Likelihood Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-poisson-loglik-curve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation of Log-Likelihood Curve\n",
        "\n",
        "The figure (Figure @fig-poisson-loglik-curve) displays the **Poisson log-likelihood** as a function of the rate parameter $\\lambda$, based on the observed patent counts.\n",
        "\n",
        "- The **x-axis** represents different values of $\\lambda$, which is the assumed average number of patents per firm.\n",
        "- The **y-axis** shows the corresponding **log-likelihood** of the data under the Poisson model for each value of $\\lambda$.\n",
        "\n",
        "We observe that the log-likelihood curve reaches its **maximum** around $\\lambda \\approx 3.68$, indicating the value that best fits the data under the Poisson assumption. This value is the **Maximum Likelihood Estimate (MLE)** of $\\lambda$.\n",
        "\n",
        "The **red dashed line** on the graph marks the **sample mean** of the observed patent counts:\n",
        "\\[\n",
        "\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y} = 3.6847\n",
        "\\]\n",
        "\n",
        "Since the log-likelihood function is concave, this plot visually confirms that the MLE is both valid and unique. The alignment between the peak of the curve and the sample mean also confirms that, under a simple Poisson model, the MLE of $\\lambda$ is the sample mean.\n",
        "\n",
        "\n",
        "### Deriving the MLE for $\\lambda$ Analytically\n",
        "\n",
        "We take the first derivative of the log-likelihood function and solve for $\\lambda$:\n",
        "\n",
        "$$\n",
        "\\log \\mathcal{L}(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n",
        "$$\n",
        "\n",
        "Taking the derivative with respect to $\\lambda$:\n",
        "\n",
        "$$\n",
        "\\frac{d}{d\\lambda} \\log \\mathcal{L}(\\lambda) = -n + \\frac{\\sum Y_i}{\\lambda}\n",
        "$$\n",
        "\n",
        "Setting the derivative equal to zero:\n",
        "\n",
        "$$\n",
        "-n + \\frac{\\sum Y_i}{\\lambda} = 0\n",
        "\\Rightarrow\n",
        "\\lambda = \\frac{\\sum Y_i}{n} = \\bar{Y}\n",
        "$$\n",
        "\n",
        "Now we verify this with code:"
      ],
      "id": "b71cdf09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: lambda-mle-analytical\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "Y = df[\"patents\"]\n",
        "lambda_mle = Y.mean()\n",
        "lambda_mle"
      ],
      "id": "lambda-mle-analytical",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Estimated $\\lambda$ from Maximum Likelihood\n",
        "\n",
        "Using numerical optimization of the Poisson log-likelihood function, we find that the maximum likelihood estimate (MLE) of $\\lambda$ is:\n",
        "\n",
        "```\n",
        "λ̂ = 3.6846666666666668\n",
        "```\n",
        "\n",
        "This value represents the estimated average number of patents per firm over the 5-year period. It corresponds to the value of $\\lambda$ that **maximizes the likelihood** of the observed data under the Poisson model.\n",
        "\n",
        "As expected, this estimate matches the **sample mean** of the observed patent counts:\n",
        "\n",
        "\\[\n",
        "\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n",
        "\\]\n",
        "\n",
        "This confirms both the analytical derivation and numerical optimization.\n",
        "\n",
        "\n",
        "\n",
        "### Maximum Likelihood Estimation of $\\lambda$ via Optimization\n",
        "\n",
        "We now find the MLE of $\\lambda$ by optimizing the log-likelihood function using `scipy.optimize.minimize` in Python."
      ],
      "id": "d6f7e8a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: mle-optimization\n",
        "#| echo: true\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import gammaln\n",
        "from scipy.optimize import minimize\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "Y_data = df[\"patents\"]\n",
        "\n",
        "def poisson_log_likelihood(y, lamb):\n",
        "    n = len(y)\n",
        "    return -n * lamb + y.sum() * np.log(lamb) - gammaln(y + 1).sum()\n",
        "\n",
        "def neg_poisson_log_likelihood(lambd):\n",
        "    return -poisson_log_likelihood(Y_data, lambd[0])\n",
        "\n",
        "initial_guess = [Y_data.mean()]\n",
        "result = minimize(neg_poisson_log_likelihood, x0=initial_guess, bounds=[(1e-5, None)])\n",
        "\n",
        "estimated_lambda = result.x[0]\n",
        "estimated_lambda"
      ],
      "id": "mle-optimization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The optimization routine returns an estimated $\\hat{\\lambda} \\approx 3.6847$, which confirms our earlier analytical result that the MLE of $\\lambda$ is equal to the sample mean under a Poisson model.\n",
        "\n",
        "\n",
        "### Estimation of Poisson Regression Model\n",
        "\n",
        "Next, we extend our simple Poisson model to a Poisson Regression Model such that $Y_i = \\text{Poisson}(\\lambda_i)$ where $\\lambda_i = \\exp(X_i'\\beta)$. The interpretation is that the success rate of patent awards is not constant across all firms ($\\lambda$) but rather is a function of firm characteristics $X_i$. Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n",
        "\n",
        "\n",
        "### Poisson Regression Log-Likelihood Function\n",
        "\n",
        "We now define the log-likelihood function for the Poisson regression model. This function takes in:\n",
        "\n",
        "- a parameter vector $\\beta$,\n",
        "- a response vector $Y$, and\n",
        "- a covariate matrix $X$,\n",
        "\n",
        "and assumes the inverse link function $g^{-1}(\\cdot) = \\exp(\\cdot)$ so that:\n",
        "\n",
        "$$\n",
        "\\lambda_i = \\exp(X_i^\\top \\beta)\n",
        "$$\n",
        "\n",
        "This guarantees $\\lambda_i > 0$ for all observations, as required in the Poisson model. The resulting log-likelihood function is:\n",
        "\n",
        "$$\n",
        "\\log \\mathcal{L}(\\beta) = \\sum_{i=1}^{n} \\left( Y_i \\log(\\lambda_i) - \\lambda_i - \\log(Y_i!) \\right)\n",
        "$$\n",
        "\n",
        "Below is the corresponding Python implementation."
      ],
      "id": "6e3ea327"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: poisson-loglik-eval\n",
        "#| echo: true\n",
        "\n",
        "def poisson_regression_log_likelihood(beta, Y, X):\n",
        "    beta = np.asarray(beta, dtype=np.float64).reshape(-1)  # Force float64 1D\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "    Y = np.asarray(Y, dtype=np.float64)\n",
        "\n",
        "    X_beta = np.dot(X, beta)\n",
        "    lambd = np.exp(X_beta)\n",
        "\n",
        "    return np.sum(Y * np.log(lambd) - lambd - gammaln(Y + 1))"
      ],
      "id": "poisson-loglik-eval",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: prepare-design-matrix\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/blueprinty.csv\")\n",
        "\n",
        "# Add a new column: age squared\n",
        "df[\"age_sq\"] = df[\"age\"] ** 2\n",
        "\n",
        "# Create dummy variables for the 'region' column\n",
        "X_region = pd.get_dummies(df[\"region\"], drop_first=True)\n",
        "\n",
        "# Create the full design matrix X\n",
        "X = pd.concat([\n",
        "    pd.Series(1, index=df.index, name=\"intercept\"),\n",
        "    df[[\"age\", \"age_sq\", \"iscustomer\"]],\n",
        "    X_region\n",
        "], axis=1)\n",
        "\n",
        "# Convert predictors and outcome to numpy arrays\n",
        "X_np = X.to_numpy(dtype=np.float64)\n",
        "Y_np = df[\"patents\"].astype(float).to_numpy()"
      ],
      "id": "prepare-design-matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_clean = pd.concat([\n",
        "    pd.Series(1.0, index=df.index, name=\"intercept\"), \n",
        "    df[[\"age\", \"age_sq\", \"iscustomer\"]].astype(float),\n",
        "    pd.get_dummies(df[\"region\"], drop_first=True).astype(float)\n",
        "], axis=1)\n",
        "\n",
        "X_np = X_clean.to_numpy(dtype=np.float64)  \n",
        "Y_np = df[\"patents\"].astype(float).to_numpy()"
      ],
      "id": "4dd8e8a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.optimize import minimize\n",
        "import numpy as np\n",
        "\n",
        "def neg_poisson_regression_log_likelihood(beta, Y, X):\n",
        "    return -poisson_regression_log_likelihood(beta, Y, X)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_np)  \n",
        "\n",
        "\n",
        "initial_beta = np.zeros(X_scaled.shape[1])  \n",
        "\n",
        "result = minimize(\n",
        "    fun=neg_poisson_regression_log_likelihood,\n",
        "    x0=initial_beta,\n",
        "    args=(Y_np, X_scaled),\n",
        "    method='BFGS'\n",
        ")\n",
        "\n",
        "beta_hat = result.x\n",
        "beta_hat"
      ],
      "id": "2ef2fef1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cov_beta = result.hess_inv\n",
        "\n",
        "se_beta = np.sqrt(np.diagonal(cov_beta))\n",
        "\n",
        "regression_output = pd.DataFrame({\n",
        "    \"Feature\": X.columns,          \n",
        "    \"Coefficient\": beta_hat,\n",
        "    \"Standard Error\": se_beta\n",
        "})\n",
        "\n",
        "regression_output"
      ],
      "id": "8d5c0238",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "glm_model = sm.GLM(Y_np, X_np, family=sm.families.Poisson())\n",
        "glm_results = glm_model.fit()\n",
        "glm_results.summary()"
      ],
      "id": "db8dced2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation of Poisson Regression Results\n",
        "\n",
        "We estimated a Poisson Generalized Linear Model (GLM) using `statsmodels.GLM` with a **log link function**, appropriate for modeling count data (e.g., number of patents per firm).\n",
        "\n",
        "---\n",
        "\n",
        "####  Model Specification\n",
        "\n",
        "- **Family**: Poisson\n",
        "- **Link Function**: Log\n",
        "- **Fitting Method**: IRLS (Iteratively Reweighted Least Squares)\n",
        "- **Data**: 1,500 engineering firms\n",
        "- **Predictors**:\n",
        "  - Intercept (constant)\n",
        "  - Age of the firm\n",
        "  - Age squared (to capture nonlinearity)\n",
        "  - Binary indicator for Blueprinty customer status\n",
        "  - Region dummy variables (with one region dropped as reference)\n",
        "\n",
        "The model takes the form:\n",
        "\n",
        "The model takes the form:\n",
        "\n",
        "$$\n",
        "\\log(\\lambda_i) = \\beta_0 + \\beta_1 \\cdot \\text{age}_i + \\beta_2 \\cdot \\text{age}_i^2 + \\beta_3 \\cdot \\text{iscustomer}_i + \\text{region effects}\n",
        "$$\n",
        "\n",
        "\n",
        "####  Model Fit Summary\n",
        "\n",
        "| Metric             | Value          | Interpretation                                           |\n",
        "|--------------------|----------------|-----------------------------------------------------------|\n",
        "| Log-Likelihood     | -3258.1        | Higher (less negative) = better fit                      |\n",
        "| Deviance           | 2143.3         | Lower values = better fit                                |\n",
        "| Pearson Chi²       | 2070.0         | Large values may suggest overdispersion                  |\n",
        "| Pseudo R² (McFadden)| 0.1360        | Model explains ~13.6% of the deviance                    |\n",
        "| No. of Iterations  | 5              | Convergence in 5 IRLS iterations                         |\n",
        "\n",
        "---\n",
        "\n",
        "####  Coefficient Interpretation\n",
        "\n",
        "| Term     | Coefficient | Std. Error | p-value | 95% CI            | Interpretation |\n",
        "|----------|-------------|------------|---------|-------------------|----------------|\n",
        "| **Intercept** | -0.509       | 0.183      | 0.005   | [-0.868, -0.150]   | Baseline log-count when all predictors = 0 |\n",
        "| **Age**       | 0.149        | 0.014      | <0.001  | [0.121, 0.176]     | Patent counts increase with age |\n",
        "| **Age²**      | -0.003       | ~0.000     | <0.001  | [-0.003, -0.002]   | Diminishing returns → inverted-U shape |\n",
        "| **Customer**  | 0.208        | 0.031      | <0.001  | [0.147, 0.268]     | Blueprinty customers have more patents |\n",
        "| **Regions**   | Mixed signs  | Not significant | 0.28–0.74 | Includes SW, NE, NW, South | No statistically significant regional effects |\n",
        "\n",
        "---\n",
        "\n",
        "####  Conclusion\n",
        "\n",
        "- There is **strong evidence** that both firm **age** and being a **Blueprinty customer** significantly affect patent output.\n",
        "- The **quadratic age term** shows an **inverted-U** pattern: the marginal gain in patents from age diminishes.\n",
        "- **Region effects** are not statistically significant in this model, suggesting that once age and customer status are controlled for, regional location has little additional predictive power.\n",
        "\n",
        "### Comparison of MLE and GLM Estimates (with Standardized Inputs)"
      ],
      "id": "31266f32"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: compare-mle-glm\n",
        "#| echo: true\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "glm_params = glm_results.params\n",
        "glm_se = glm_results.bse\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"MLE Estimate\": beta_hat,\n",
        "    \"MLE Std. Err\": se_beta,\n",
        "    \"GLM Estimate\": glm_params,\n",
        "    \"GLM Std. Err\": glm_se\n",
        "})\n",
        "\n",
        "comparison_df"
      ],
      "id": "compare-mle-glm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation of MLE and GLM Estimates\n",
        "\n",
        "The table above compares coefficient estimates and standard errors obtained from two estimation methods for a Poisson regression model: (1) a manually implemented Maximum Likelihood Estimation (MLE) using `scipy.optimize.minimize`, and (2) a Generalized Linear Model (GLM) using `statsmodels.GLM`.\n",
        "\n",
        "Both models were fitted to the same dataset with standardized predictors, including an intercept, firm age, age squared, Blueprinty customer status, and region indicators (excluding the reference region).\n",
        "\n",
        "#### Model Agreement\n",
        "\n",
        "The MLE and GLM approaches yield consistent results in both direction and relative magnitude of the coefficient estimates. Standard errors are also closely aligned, suggesting that both estimation procedures are implemented correctly and produce stable results under comparable scaling.\n",
        "\n",
        "#### Variable-Specific Observations\n",
        "\n",
        "- **Intercept**: The MLE method estimates the intercept at zero, while the GLM method returns a slightly negative value (-0.509). This discrepancy is likely attributable to differences in standardization treatment, particularly in how the intercept is handled.\n",
        "\n",
        "- **Age**: Both models identify age as a positive and statistically significant predictor of patent activity. The positive coefficient indicates that older firms tend to receive more patents, holding other variables constant.\n",
        "\n",
        "- **Age Squared**: The negative coefficient on age squared confirms a concave (inverted-U) relationship between age and patent counts. This suggests diminishing returns to age—older firms experience reduced patent growth beyond a certain point.\n",
        "\n",
        "- **Customer Status**: The coefficient for the `iscustomer` variable is positive and statistically significant in both models. This provides empirical support for the claim that firms using Blueprinty's software tend to secure more patents than non-customers, after adjusting for other firm characteristics.\n",
        "\n",
        "- **Region Indicators**: None of the regional dummy variables are statistically significant in either model. This suggests that, conditional on age and customer status, regional differences do not have a meaningful impact on patent outcomes in this dataset.\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "The high degree of alignment between the MLE and GLM results provides confidence in the robustness of the findings. The evidence strongly supports the role of firm age and Blueprinty software usage in explaining variation in patent counts, while region appears to play a minor role.\n",
        "\n",
        "\n",
        "### Estimating the Effect of Blueprinty Software on Patent Success\n",
        "\n",
        "To interpret the model in terms of predicted patent counts (rather than log-count coefficients), we simulate two counterfactual scenarios:\n",
        "\n",
        "- `X_0`: Every firm is treated as a **non-customer** (`iscustomer = 0`)\n",
        "- `X_1`: Every firm is treated as a **customer** (`iscustomer = 1`)\n",
        "\n",
        "Using the fitted model coefficients, we compare the predicted number of patents under both cases and compute the average difference."
      ],
      "id": "4cd13d43"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_no_customer = X_clean.copy()\n",
        "X_no_customer.loc[:, \"iscustomer\"] = 0\n",
        "\n",
        "X_as_customer = X_clean.copy()\n",
        "X_as_customer.loc[:, \"iscustomer\"] = 1\n",
        "X_no_cust_np = X_no_customer.to_numpy()\n",
        "X_yes_cust_np = X_as_customer.to_numpy()\n",
        "patents_pred_no = glm_results.predict(X_no_cust_np)\n",
        "patents_pred_yes = glm_results.predict(X_yes_cust_np)\n",
        "\n",
        "effect_of_customer = np.mean(patents_pred_yes - patents_pred_no)\n",
        "effect_of_customer\n"
      ],
      "id": "e4623901",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Estimated Effect of Blueprinty's Software on Patent Success\n",
        "\n",
        "To interpret the practical impact of Blueprinty's software, we simulated two counterfactual scenarios:\n",
        "\n",
        "- In the first, we treated all firms as **non-customers** (`iscustomer = 0`).\n",
        "- In the second, we treated all firms as **customers** (`iscustomer = 1`).\n",
        "\n",
        "We used our fitted Poisson regression model to predict the number of patents under each scenario. The difference in predicted patent counts for each firm reflects the estimated effect of Blueprinty's software. We then took the **average of these differences** across all firms in the dataset.\n",
        "\n",
        "The result:\n",
        "\n",
        "```\n",
        "Average treatment effect ≈ 0.793 patents\n",
        "```\n",
        "\n",
        "#### Interpretation:\n",
        "\n",
        "On average, firms that use Blueprinty's software are predicted to obtain approximately **0.79 more patents** over the observed period compared to firms that do not use the software, **holding all other factors constant** (including age and region).\n",
        "\n",
        "This suggests a **meaningful positive association** between Blueprinty software usage and patent output. While this estimate does not imply causality, it provides strong evidence that customers of Blueprinty tend to outperform non-customers in terms of patent success when matched on observable characteristics.\n",
        "\n",
        "\n",
        "\n",
        "## AirBnB Case Study\n",
        "\n",
        "### Introduction\n",
        "\n",
        "AirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City.  The data include the following variables:\n",
        "\n",
        ":::: {.callout-note collapse=\"true\"}\n",
        "### Variable Definitions\n",
        "\n",
        "    - `id` = unique ID number for each unit\n",
        "    - `last_scraped` = date when information scraped\n",
        "    - `host_since` = date when host first listed the unit on Airbnb\n",
        "    - `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n",
        "    - `room_type` = Entire home/apt., Private room, or Shared room\n",
        "    - `bathrooms` = number of bathrooms\n",
        "    - `bedrooms` = number of bedrooms\n",
        "    - `price` = price per night (dollars)\n",
        "    - `number_of_reviews` = number of reviews for the unit on Airbnb\n",
        "    - `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n",
        "    - `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n",
        "    - `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n",
        "    - `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "## Modeling Airbnb Booking Activity\n",
        "\n",
        "In this section, we assume that the number of reviews is a valid proxy for the number of bookings. We conduct exploratory data analysis, clean the dataset, and estimate a Poisson regression model to explain variation in review counts based on listing characteristics.\n",
        "\n",
        "1. check the dataset"
      ],
      "id": "a1c8601a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: airbnb-cleaning\n",
        "#| echo: false\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"/Users/hanhuazhu/Desktop/mywebsite/blog/project2/airbnb.csv\")\n",
        "df.head()"
      ],
      "id": "airbnb-cleaning",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary Statistics of Key Variables\n",
        "\n",
        "Before modeling, we examine basic descriptive statistics to understand the scale and distribution of the data."
      ],
      "id": "b1d91673"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: airbnb-summary-stats\n",
        "#| echo: false\n",
        "# Drop ID and timestamp columns\n",
        "cols_to_keep = [\n",
        "    \"days\", \"bathrooms\", \"bedrooms\", \"price\", \"number_of_reviews\",\n",
        "    \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\"\n",
        "]\n",
        "\n",
        "summary_clean = df[cols_to_keep].describe().T.round(2)\n",
        "summary_clean"
      ],
      "id": "airbnb-summary-stats",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: summary-categoricals\n",
        "#| echo: false\n",
        "\n",
        "# Summarize categorical variables\n",
        "categorical_summary = df[[\"room_type\", \"instant_bookable\"]].astype(str).describe().T\n",
        "categorical_summary"
      ],
      "id": "summary-categoricals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary Statistics for Numeric Variables\n",
        "\n",
        "We present summary statistics for selected numeric variables that will be used in our modeling. This includes central tendency, dispersion, and count of non-missing observations."
      ],
      "id": "b4bd0935"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: airbnb-summary-numeric\n",
        "#| echo: false\n",
        "\n",
        "# Select only relevant numeric variables for modeling\n",
        "numeric_cols = [\n",
        "    \"days\", \"bathrooms\", \"bedrooms\", \"price\",\n",
        "    \"number_of_reviews\", \"review_scores_cleanliness\",\n",
        "    \"review_scores_location\", \"review_scores_value\"\n",
        "]\n",
        "\n",
        "# Filter and summarize\n",
        "numeric_summary = df[numeric_cols].describe().T.round(2)\n",
        "\n",
        "# Rename columns for readability\n",
        "numeric_summary = numeric_summary.rename(columns={\n",
        "    \"count\": \"N\", \"mean\": \"Mean\", \"std\": \"Std Dev\",\n",
        "    \"min\": \"Min\", \"25%\": \"Q1\", \"50%\": \"Median\",\n",
        "    \"75%\": \"Q3\", \"max\": \"Max\"\n",
        "})\n",
        "\n",
        "numeric_summary"
      ],
      "id": "airbnb-summary-numeric",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: airbnb-eda\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "#| fig-cap: Distribution of Number of Reviews\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Histogram of number of reviews\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df[\"number_of_reviews\"], bins=50, kde=False)\n",
        "plt.xlabel(\"Number of Reviews\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Review Counts (Proxy for Bookings)\")\n",
        "plt.xlim(0, 100)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "airbnb-eda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This histogram shows a highly right-skewed distribution of the number of reviews per Airbnb listing. Most listings receive fewer than 20 reviews, with a sharp drop-off beyond that point. A small number of listings have 50 or more reviews, indicating that a few highly booked properties dominate review volume. This skewness supports the use of a Poisson (or possibly negative binomial) model for count-based regression.\n",
        "\n",
        "### Distribution of Number of Reviews by Room Type\n",
        "\n",
        "The plot below shows the full distribution of review counts (a proxy for bookings) across different room types. Violin plots provide more detail than boxplots by visualizing the density of the data."
      ],
      "id": "09c95500"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: plot-reviews-by-room-type\n",
        "#| fig-cap: Distribution of Number of Reviews by Room Type\n",
        "#| warning: false\n",
        "#| echo: false\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load data (if not already loaded)\n",
        "df = pd.read_csv(\"~/Downloads/airbnb.csv\")  # adjust path if needed\n",
        "\n",
        "# Create violin plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(\n",
        "    data=df,\n",
        "    x=\"room_type\",\n",
        "    y=\"number_of_reviews\",\n",
        "    inner=\"quartile\",\n",
        "    cut=0,\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"Distribution of Number of Reviews by Room Type\")\n",
        "plt.xlabel(\"Room Type\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "plot-reviews-by-room-type",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The violin plot above illustrates the distribution of the number of reviews (used here as a proxy for bookings) across different room types: Private Room, Entire Home/Apt, and Shared Room. Each distribution is highly right-skewed, with the majority of listings receiving relatively few reviews and a long tail of listings with many.\n",
        "\n",
        "While all room types follow a similar overall pattern, there are some subtle differences in the spread and density. Private rooms and entire home/apartment listings show comparable distributions, both with slightly higher concentrations of listings receiving moderate review counts. Shared rooms, on the other hand, exhibit a more compressed distribution, suggesting they may receive fewer bookings overall, or are listed less frequently.\n",
        "\n",
        "Overall, the visual supports including `room_type` as a categorical predictor in a Poisson regression model, though the similarities across categories suggest that its impact on bookings may be modest compared to other factors like price or location.\n",
        "\n",
        " ## Exploratory Visualizations\n",
        "\n",
        "We include several plots to explore how various listing characteristics relate to the number of reviews, which serves as a proxy for bookings.\n",
        "\n",
        "---\n",
        "\n",
        "### Reviews vs. Price\n",
        "\n",
        "This scatter plot shows how review counts vary with listing price. Since price is highly skewed, we limit the x-axis to exclude extreme outliers."
      ],
      "id": "54436d4f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: plot-reviews-vs-price\n",
        "#| fig-cap: Review Counts vs. Listing Price\n",
        "#| warning: false\n",
        "#| echo: false\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=df, x=\"price\", y=\"number_of_reviews\", alpha=0.3)\n",
        "plt.xlim(0, 500)\n",
        "plt.xlabel(\"Price (USD)\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.title(\"Review Counts vs. Listing Price\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "plot-reviews-vs-price",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Reviews vs. Days Listed\n",
        "\n",
        "This plot explores whether longer-listed units tend to accumulate more reviews over time."
      ],
      "id": "5831a071"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: plot-reviews-vs-days\n",
        "#| fig-cap: Review Counts vs. Days Listed\n",
        "#| warning: false\n",
        "#| echo: false\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=df, x=\"days\", y=\"number_of_reviews\", alpha=0.3)\n",
        "plt.xlim(0, 3000)\n",
        "plt.xlabel(\"Days Listed\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.title(\"Review Counts vs. Days Listed\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "plot-reviews-vs-days",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Reviews by Instant Bookable Status\n",
        "\n",
        "Boxplot comparing listings that are instantly bookable versus not. This can reveal whether frictionless booking impacts demand."
      ],
      "id": "e2074c68"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: boxplot-instant-bookable\n",
        "#| fig-cap: Number of Reviews by Instant Bookable Status\n",
        "#| warning: false\n",
        "#| echo: false\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(data=df, x=\"instant_bookable\", y=\"number_of_reviews\")\n",
        "plt.xlabel(\"Instant Bookable (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.title(\"Review Counts by Instant Bookable Status\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "boxplot-instant-bookable",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Reviews by Cleanliness Score\n",
        "\n",
        "This boxplot evaluates whether listings with higher cleanliness ratings tend to get more reviews."
      ],
      "id": "e9cfa9f2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: boxplot-cleanliness\n",
        "#| fig-cap: Number of Reviews by Cleanliness Score\n",
        "#| warning: false\n",
        "#| echo: false\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"review_scores_cleanliness\", y=\"number_of_reviews\")\n",
        "plt.xlabel(\"Cleanliness Score (1–10)\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.title(\"Review Counts by Cleanliness Rating\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "boxplot-cleanliness",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Listings per Room Type\n",
        "\n",
        "This count plot shows the volume of listings per room type. It provides useful context on sample size for each category."
      ],
      "id": "d942bd71"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: count-room-type\n",
        "#| fig-cap: Number of Listings by Room Type\n",
        "#| warning: false\n",
        "#| echo: false\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(data=df, x=\"room_type\", order=df[\"room_type\"].value_counts().index)\n",
        "plt.title(\"Listing Counts by Room Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xlabel(\"Room Type\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "count-room-type",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploratory Visualizations: Key Insights\n",
        "\n",
        "#### Reviews vs. Price\n",
        "\n",
        "The first scatter plot shows that review counts are highest for listings priced between \\$50 and \\$150. While there are some listings with high prices and high review counts, the general trend suggests diminishing review volume at higher price points. This indicates that extremely expensive listings may be less frequently booked, or cater to niche audiences.\n",
        "\n",
        "#### Reviews vs. Days Listed\n",
        "\n",
        "Listings that have been active on the platform for a longer time tend to accumulate more reviews, as shown in the second plot. The positive trend aligns with expectations: more time on the platform allows for more bookings and reviews to accumulate. However, the scatter remains wide, suggesting that duration alone does not fully explain booking activity.\n",
        "\n",
        "#### Reviews by Instant Bookable Status\n",
        "\n",
        "The third plot compares review counts between listings that are instantly bookable and those that are not. While both groups exhibit a similar spread, instantly bookable listings show slightly higher medians and more frequent high-review outliers. This implies that reducing booking friction may enhance listing performance.\n",
        "\n",
        "#### Reviews by Cleanliness Rating\n",
        "\n",
        "Review counts appear to increase with higher cleanliness scores, particularly between ratings 7 and 10. Listings rated 9 or 10 in cleanliness show a higher density of large review counts, suggesting that cleanliness positively correlates with booking success and guest satisfaction.\n",
        "\n",
        "#### Listing Counts by Room Type\n",
        "\n",
        "The bar chart shows that \"Entire home/apt\" and \"Private room\" are by far the most common listing types, while \"Shared room\" is relatively rare. This distribution reflects user preferences for privacy and autonomy in accommodations, and justifies including room type as a categorical predictor in modeling.\n",
        "\n",
        "\n",
        "\n",
        "### Poisson Regression Model: Predicting Review Counts from Listing Features\n",
        "\n",
        "We use a Poisson regression model to predict the number of reviews (a proxy for bookings) based on listing characteristics, amenities, and quality indicators."
      ],
      "id": "f963592f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: poisson-glm-final\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load and clean data\n",
        "df = pd.read_csv(\"~/Downloads/airbnb.csv\")\n",
        "\n",
        "# Select relevant variables and drop missing rows\n",
        "selected_vars = [\n",
        "    \"days\", \"bathrooms\", \"bedrooms\", \"price\",\n",
        "    \"review_scores_cleanliness\", \"review_scores_location\",\n",
        "    \"review_scores_value\", \"instant_bookable\", \"room_type\"\n",
        "]\n",
        "df_model = df[selected_vars + [\"number_of_reviews\"]].dropna()\n",
        "\n",
        "# Binary encode instant_bookable\n",
        "df_model[\"instant_bookable\"] = (df_model[\"instant_bookable\"] == \"t\").astype(int)\n",
        "\n",
        "# One-hot encode room_type (drop reference)\n",
        "room_dummies = pd.get_dummies(df_model[\"room_type\"], drop_first=True)\n",
        "\n",
        "# Construct design matrix\n",
        "X_model = pd.concat([\n",
        "    pd.Series(1, index=df_model.index, name=\"intercept\"),\n",
        "    df_model[[\n",
        "        \"days\", \"bathrooms\", \"bedrooms\", \"price\",\n",
        "        \"review_scores_cleanliness\", \"review_scores_location\",\n",
        "        \"review_scores_value\", \"instant_bookable\"\n",
        "    ]],\n",
        "    room_dummies\n",
        "], axis=1)\n",
        "\n",
        "# Response variable\n",
        "Y_model = df_model[\"number_of_reviews\"]\n",
        "\n",
        "# Ensure both X and Y are float64 and index-aligned\n",
        "X_model = X_model.astype(float)\n",
        "Y_model = Y_model.astype(float)\n",
        "\n",
        "# Fit GLM Poisson model\n",
        "glm_model = sm.GLM(Y_model, X_model, family=sm.families.Poisson())\n",
        "glm_results = glm_model.fit()\n",
        "\n",
        "# Display summary\n",
        "glm_results.summary()"
      ],
      "id": "poisson-glm-final",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation of Poisson Regression Results\n",
        "\n",
        "The table above summarizes the results of a Poisson regression model predicting the number of reviews a listing receives based on various listing attributes.\n",
        "\n",
        "#### Model Fit\n",
        "\n",
        "- **Log-Likelihood**: –524,180  \n",
        "- **Pseudo R²**: 0.6840  \n",
        "- **No. of Observations**: 30,160  \n",
        "- The model explains a substantial amount of variation in review counts, as indicated by the high Pseudo R² value (0.684), which is unusually strong for a Poisson model.\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Coefficients and Interpretation\n",
        "\n",
        "All coefficients are interpreted on the **log-count scale** due to the log-link function. A positive coefficient means that the predictor increases the expected number of reviews, holding other variables constant.\n",
        "\n",
        "| Variable               | Coefficient | Interpretation |\n",
        "|------------------------|-------------|----------------|\n",
        "| **Intercept**          | 3.4980      | Baseline expected log-count of reviews when all predictors are zero. |\n",
        "| **Days Listed**        | 5.07e-05    | Listings on the platform longer tend to have more reviews. Small but significant. |\n",
        "| **Bathrooms**          | –0.1177     | Each additional bathroom is associated with a decrease in expected reviews, possibly reflecting listing type or overpricing. |\n",
        "| **Bedrooms**           | 0.0741      | Each additional bedroom increases expected review counts, likely due to larger or more desirable units. |\n",
        "| **Price**              | –1.79e-05   | Small negative effect; higher-priced listings may receive fewer bookings (and reviews). |\n",
        "| **Review Score: Cleanliness** | 0.1131 | Higher cleanliness ratings are associated with more reviews, suggesting guest satisfaction leads to more repeat use and visibility. |\n",
        "| **Review Score: Location**    | –0.0769 | Surprisingly negative; may indicate that extremely central or remote listings attract niche usage patterns. |\n",
        "| **Review Score: Value**       | –0.0911 | Negative effect may reflect that \"value\" is inversely related to pricing in perception. |\n",
        "| **Instant Bookable**   | 0.3459      | Listings that are instantly bookable get significantly more reviews, indicating reduced friction increases booking volume. |\n",
        "\n",
        "---\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "The model reveals that factors such as **number of bedrooms**, **cleanliness**, and **instant bookable status** are strong positive predictors of booking volume (as proxied by review count). In contrast, **higher prices**, more bathrooms, and lower perceived value are associated with fewer bookings. These insights are helpful for hosts optimizing listing strategies and Airbnb improving search algorithms.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Final Reflections\n",
        "\n",
        "This project showcased how Poisson regression can be applied to understand patterns in real-world count data. Whether analyzing how often firms receive patents or how frequently Airbnb listings accumulate reviews, the objective was to identify which features meaningfully influence these outcomes.\n",
        "\n",
        "The Blueprinty analysis emphasized how organizational characteristics—like age and region—affect innovation outcomes, and showed a measurable advantage tied to using the firm’s software. In contrast, the Airbnb study focused on listing attributes such as pricing, room setup, cleanliness ratings, and booking convenience. Across both cases, Poisson modeling proved valuable in capturing the relationship between structured inputs and count-based performance measures.\n",
        "\n",
        "Constructing the likelihood function manually, then benchmarking it against a built-in GLM, offered more than just technical comparison—it reinforced the benefits of building from the ground up. While the outputs were often aligned, the hands-on process highlighted important details around implementation and diagnostics that wouldn’t be as apparent using pre-built packages alone.\n",
        "\n",
        "In sum, this work illustrates how statistically grounded, interpretable models can offer clear insights for data-driven decision-making across a variety of practical settings.\n"
      ],
      "id": "eadaea30"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/hanhuazhu/anaconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}