[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nHanhua Zhu\n\n\nApr 22, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/hw1_questions (4).html",
    "href": "blog/project1/hw1_questions (4).html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale natural field experiment to test the effectiveness of different fundraising strategies. They sent out over 50,000 fundraising letters to prior donors of a nonprofit organization, randomly assigning recipients to one of several treatment groups.\nThe experiment tested whether the presence of a matching donation offer (e.g., for every $1 donated, the organization receives $2, $3, or $4 total depending on the match ratio) would increase both the likelihood of giving and the amount donated. The matching ratios varied between 1:1, 2:1, and 3:1. In addition, the letters varied the maximum match amount (e.g., $25,000, $50,000, or $100,000) and the suggested donation amount, which was calculated based on each recipient’s highest prior donation.\nRecipients were randomly assigned to treatment groups, making this a clean experimental design for causal inference. The primary outcomes were whether someone donated and how much they gave. These results help inform how nonprofits can design more effective fundraising campaigns.\nThe results were published in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate some of their core findings using the original dataset and statistical methods."
  },
  {
    "objectID": "blog/project1/hw1_questions (4).html#introduction",
    "href": "blog/project1/hw1_questions (4).html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale natural field experiment to test the effectiveness of different fundraising strategies. They sent out over 50,000 fundraising letters to prior donors of a nonprofit organization, randomly assigning recipients to one of several treatment groups.\nThe experiment tested whether the presence of a matching donation offer (e.g., for every $1 donated, the organization receives $2, $3, or $4 total depending on the match ratio) would increase both the likelihood of giving and the amount donated. The matching ratios varied between 1:1, 2:1, and 3:1. In addition, the letters varied the maximum match amount (e.g., $25,000, $50,000, or $100,000) and the suggested donation amount, which was calculated based on each recipient’s highest prior donation.\nRecipients were randomly assigned to treatment groups, making this a clean experimental design for causal inference. The primary outcomes were whether someone donated and how much they gave. These results help inform how nonprofits can design more effective fundraising campaigns.\nThe results were published in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate some of their core findings using the original dataset and statistical methods."
  },
  {
    "objectID": "blog/project1/hw1_questions (4).html#data",
    "href": "blog/project1/hw1_questions (4).html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe load and explore the dataset from Karlan and List (2007).\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\ndata = pd.read_stata(\"/Users/hanhuazhu/Downloads/karlan_list_2007 (2).dta\")\n\n# Preview first few rows\ndata.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n#:::: {.callout-note collapse=“true”}\n\n\n\n\n\n\n\n##\nVariable\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n::::\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWe test whether months since last donation (mrm2) differ between treatment and control groups using both a t-test and a linear regression.\n\n# T-test for mrm2\ntreat = data[data['treatment'] == 1]['mrm2'].dropna()\ncontrol = data[data['treatment'] == 0]['mrm2'].dropna()\n\nt_stat, p_val = stats.ttest_ind(treat, control, equal_var=False)\nprint(f\"T-test result for mrm2:\\nT-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nT-test result for mrm2:\nT-statistic: 0.120, p-value: 0.905\n\n\n\n# OLS regression: mrm2 ~ treatment\nmodel = smf.ols(\"mrm2 ~ treatment\", data=data).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nmrm2\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.01428\n\n\nDate:\nTue, 22 Apr 2025\nProb (F-statistic):\n0.905\n\n\nTime:\n20:53:47\nLog-Likelihood:\n-1.9585e+05\n\n\nNo. Observations:\n50082\nAIC:\n3.917e+05\n\n\nDf Residuals:\n50080\nBIC:\n3.917e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n12.9981\n0.094\n138.979\n0.000\n12.815\n13.181\n\n\ntreatment\n0.0137\n0.115\n0.119\n0.905\n-0.211\n0.238\n\n\n\n\n\n\n\n\nOmnibus:\n8031.352\nDurbin-Watson:\n2.004\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n12471.135\n\n\nSkew:\n1.163\nProb(JB):\n0.00\n\n\nKurtosis:\n3.751\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nInterpretation: Both the t-test and linear regression for mrm2 (months since last donation) show no statistically significant difference between treatment and control groups.\n\n\nThe t-test gave a p-value of 0.905, indicating no meaningful difference.\nThe OLS regression estimated the treatment effect at 0.0137, also with a p-value of 0.905.\n\nThese results confirm the success of the randomization: the treatment and control groups are statistically similar in terms of prior donation behavior. This supports the internal validity of the experiment and aligns with the purpose of Table 1 in Karlan and List (2007), which shows balance across multiple variables to reassure readers that observed treatment effects are not confounded by pre-existing group differences."
  },
  {
    "objectID": "blog/project1/hw1_questions (4).html#experimental-results",
    "href": "blog/project1/hw1_questions (4).html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\nCharitable Contribution Made\nWe examine whether the treatment group had a higher donation rate compared to the control group.\n\n# Barplot of donation rate by treatment\nsns.barplot(data=data, x=\"treatment\", y=\"gave\", ci=None)\nplt.xticks([0, 1], [\"Control\", \"Treatment\"])\nplt.ylabel(\"Proportion Donated\")\nplt.title(\"Donation Rate by Treatment Group\")\nplt.show()\n\n/var/folders/n6/y_4fsn553lq6_fzmfb11cjth0000gn/T/ipykernel_330/113081018.py:2: FutureWarning:\n\n\n\nThe `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\n\n# T-test on binary outcome (gave)\ntreat = data[data['treatment'] == 1]['gave']\ncontrol = data[data['treatment'] == 0]['gave']\n\nt_stat, p_val = stats.ttest_ind(treat, control, equal_var=False)\nprint(f\"T-test for 'gave':\\nT-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n\nT-test for 'gave':\nT-statistic: 3.209, p-value: 0.001\n\n\n\n# Bivariate OLS regression: gave ~ treatment\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n9.618\n\n\nDate:\nTue, 22 Apr 2025\nProb (F-statistic):\n0.00193\n\n\nTime:\n20:53:47\nLog-Likelihood:\n26630.\n\n\nNo. Observations:\n50083\nAIC:\n-5.326e+04\n\n\nDf Residuals:\n50081\nBIC:\n-5.324e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0179\n0.001\n16.225\n0.000\n0.016\n0.020\n\n\ntreatment\n0.0042\n0.001\n3.101\n0.002\n0.002\n0.007\n\n\n\n\n\n\n\n\nOmnibus:\n59814.280\nDurbin-Watson:\n2.005\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n4317152.727\n\n\nSkew:\n6.740\nProb(JB):\n0.00\n\n\nKurtosis:\n46.440\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Probit regression: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\nprobit_model.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nTue, 22 Apr 2025\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n20:53:47\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n\n\nInterpretation of Experimental Results\nThe evidence suggests that being assigned to the treatment group — receiving a matching donation offer — significantly increased the likelihood of making a charitable donation.\n\nThe bar plot shows a noticeable difference in donation rates between the treatment and control groups.\nThe t-test reveals a statistically significant difference in donation behavior (T = 3.209, p = 0.001), meaning the treatment group donated at a higher rate than the control group.\nThe OLS regression confirms this finding. The treatment coefficient is 0.0042, with a p-value of 0.002, indicating that assignment to treatment increases the probability of donating by about 0.42 percentage points.\nThe Probit regression also supports this: the coefficient on treatment is 0.0868 (p = 0.002), again showing a positive and statistically significant effect on the likelihood of giving.\n\nOverall, these results replicate the findings in Karlan and List (2007): matching donations increase the probability of giving, even if the actual increase is modest in absolute terms. The consistency across all three statistical approaches (t-test, OLS, and probit) strengthens the causal interpretation of the results. This supports the idea that even small nudges like matching offers can influence donor behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\nDifferences between Match Rates\nWe explore whether larger match ratios (e.g., 2:1 or 3:1) result in higher likelihoods of donating compared to a 1:1 match.\n\n\n\nT-tests for Match Ratios\n\n# Filter only treatment group and each match ratio\nratio1 = data[(data['treatment'] == 1) & (data['ratio'] == 1)]['gave']\nratio2 = data[(data['treatment'] == 1) & (data['ratio'] == 2)]['gave']\nratio3 = data[(data['treatment'] == 1) & (data['ratio'] == 3)]['gave']\n\n# T-tests\nprint(\"2:1 vs 1:1\")\nprint(stats.ttest_ind(ratio2, ratio1, equal_var=False))\n\nprint(\"\\n3:1 vs 2:1\")\nprint(stats.ttest_ind(ratio3, ratio2, equal_var=False))\n\n2:1 vs 1:1\nTtestResult(statistic=0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836)\n\n3:1 vs 2:1\nTtestResult(statistic=0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778)\n\n\n\nInterpretation:\nThese t-tests compare donation rates for each match ratio within the treatment group.\n- The 2:1 vs 1:1 test shows a [insert p-value here], and\n- The 3:1 vs 2:1 test shows a [insert p-value here].\nIn both comparisons, the p-values are relatively large, suggesting no statistically significant difference in donation likelihood across match sizes. This supports Karlan and List’s finding that increasing the match ratio does not meaningfully improve the effectiveness of the match offer.\n\n\n\n\nRegression on Match Ratio (Categorical)\n\n# Filter for treatment group and valid match ratios\nmatch_data = data[(data['treatment'] == 1) & (data['ratio'].isin([1, 2, 3]))].copy()\n\n# Properly set 'ratio' as a categorical variable with 1:1 as the baseline\nmatch_data['ratio'] = pd.Categorical(match_data['ratio'], categories=[1, 2, 3])\n\n# Run the regression: donation behavior by match ratio\nmodel = smf.ols(\"gave ~ C(ratio)\", data=match_data).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nTue, 22 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n20:53:48\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nC(ratio)[T.2]\n0.0019\n0.002\n0.958\n0.338\n-0.002\n0.006\n\n\nC(ratio)[T.3]\n0.0020\n0.002\n1.008\n0.313\n-0.002\n0.006\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nInterpretation:\nThe regression estimates donation rates for each match ratio using the 1:1 match as the baseline (intercept = 2.07%).\n- The coefficient for 2:1 is 0.0019 (p = 0.338), and\n- The coefficient for 3:1 is 0.0020 (p = 0.313).\nThese coefficients are very small and not statistically significant, indicating that higher match ratios do not meaningfully increase the likelihood of giving beyond what is achieved with a 1:1 match.\nThis supports the key finding in Karlan and List (2007): the existence of a match offer increases donations, but increasing the ratio (e.g., from 1:1 to 3:1) does not further boost effectiveness.\n\n\n\nResponse Rate Differences from Raw Data and Model\n\n# Group-level mean donation rates\nratio1 = data[(data['treatment'] == 1) & (data['ratio'] == 1)]['gave']\nratio2 = data[(data['treatment'] == 1) & (data['ratio'] == 2)]['gave']\nratio3 = data[(data['treatment'] == 1) & (data['ratio'] == 3)]['gave']\n\nmean1 = ratio1.mean()\nmean2 = ratio2.mean()\nmean3 = ratio3.mean()\n\nprint(f\"Response Rate 1:1 = {mean1:.4f}\")\nprint(f\"Response Rate 2:1 = {mean2:.4f}\")\nprint(f\"Response Rate 3:1 = {mean3:.4f}\")\n\nprint(f\"\\n2:1 - 1:1 = {mean2 - mean1:.4f}\")\nprint(f\"3:1 - 2:1 = {mean3 - mean2:.4f}\")\n\nResponse Rate 1:1 = 0.0207\nResponse Rate 2:1 = 0.0226\nResponse Rate 3:1 = 0.0227\n\n2:1 - 1:1 = 0.0019\n3:1 - 2:1 = 0.0001\n\n\n\n# Model-based differences from regression coefficients\ncoef = model.params\n\nprint(\"\\nModel-Based Differences:\")\nprint(f\"2:1 - 1:1 = {coef['C(ratio)[T.2]']:.4f}\")\nprint(f\"3:1 - 1:1 = {coef['C(ratio)[T.3]']:.4f}\")\nprint(f\"3:1 - 2:1 = {coef['C(ratio)[T.3]'] - coef['C(ratio)[T.2]']:.4f}\")\n\n\nModel-Based Differences:\n2:1 - 1:1 = 0.0019\n3:1 - 1:1 = 0.0020\n3:1 - 2:1 = 0.0001\n\n\n\nInterpretation:\nBoth the raw response rate differences and the model-based regression estimates suggest that increasing the match ratio from 1:1 to 2:1 leads to a very small increase in the probability of giving (approximately 0.0019, or 0.19 percentage points).\nIncreasing the ratio further from 2:1 to 3:1 adds virtually no additional effect — a difference of just 0.0001, or 0.01 percentage points. These differences are not only small in magnitude but also statistically insignificant based on earlier t-tests and regression outputs.\nThe fact that the raw differences and regression coefficients are nearly identical provides strong evidence that these small effects are consistent across estimation approaches.\nIn line with Karlan and List (2007), we conclude that the presence of a match offer matters, but larger match ratios (like 3:1) do not provide additional benefit over a standard 1:1 match. This supports their interpretation that psychological or motivational factors may be triggered by any match, not necessarily a more generous one.\n\n\n\n\n\nSummary\n&gt; **Conclusion**:  \n&gt; Neither the t-tests nor the regression provide strong evidence that increasing the match ratio from 1:1 to 2:1 or 3:1 significantly increases the donation response rate. The estimated differences are small and statistically insignificant. These findings replicate Karlan and List’s claim on page 8 that “larger match ratios do not provide additional lift,” and suggest that announcing any match offer may be sufficient to nudge donation behavior — but increasing the ratio adds little extra power.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nFull Sample Regression (Includes Non-Donors)\n\n# OLS regression on full sample\nmodel_full = smf.ols(\"amount ~ treatment\", data=data).fit()\nmodel_full.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n3.461\n\n\nDate:\nTue, 22 Apr 2025\nProb (F-statistic):\n0.0628\n\n\nTime:\n20:53:48\nLog-Likelihood:\n-1.7946e+05\n\n\nNo. Observations:\n50083\nAIC:\n3.589e+05\n\n\nDf Residuals:\n50081\nBIC:\n3.589e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.8133\n0.067\n12.063\n0.000\n0.681\n0.945\n\n\ntreatment\n0.1536\n0.083\n1.861\n0.063\n-0.008\n0.315\n\n\n\n\n\n\n\n\nOmnibus:\n96861.113\nDurbin-Watson:\n2.008\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n240735713.635\n\n\nSkew:\n15.297\nProb(JB):\n0.00\n\n\nKurtosis:\n341.269\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nConditional on Donation Only\n\n# Filter to only those who gave a donation\ndonors = data[data['gave'] == 1]\n\n# OLS regression among donors only\nmodel_donors = smf.ols(\"amount ~ treatment\", data=donors).fit()\nmodel_donors.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nTue, 22 Apr 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n20:53:48\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\ntreatment\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nHistogram of Donation Amounts: Treatment Group\n\nsns.histplot(donors[donors['treatment'] == 1]['amount'], bins=30)\nplt.axvline(donors[donors['treatment'] == 1]['amount'].mean(), color='red', linestyle='--', label='Mean')\nplt.title(\"Donation Amounts – Treatment Group\")\nplt.xlabel(\"Amount\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nHistogram of Donation Amounts: Control Group\n\nsns.histplot(donors[donors['treatment'] == 0]['amount'], bins=30)\nplt.axvline(donors[donors['treatment'] == 0]['amount'].mean(), color='red', linestyle='--', label='Mean')\nplt.title(\"Donation Amounts – Control Group\")\nplt.xlabel(\"Amount\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nInterpretation:\nIn the regression using the full sample, we find that the treatment group donated $0.15 more on average than the control group. However, this result is not statistically significant (p = 0.063), meaning we cannot rule out that the difference is due to random chance.\nIn the donor-only regression, we isolate just the people who made a donation and ask: do those in the treatment group give more than those in the control? Here, the treatment coefficient is -1.67, again not statistically significant (p = 0.561). In fact, the sign of the effect is slightly negative.\nThe histograms show that donation amounts are heavily skewed, with most donations under $100. The means for treatment and control are both around $45–46, with very similar distributions.\nConclusion: The treatment (i.e., receiving a matching offer) appears to influence whether people give, but not how much they give. The full-sample regression can be interpreted causally because of random assignment, while the donor-only regression cannot, since it conditions on a post-treatment behavior (selection bias).\nOverall, our findings replicate Karlan and List (2007): matching gifts increase response rates, but do not significantly affect the donation size conditional on giving."
  },
  {
    "objectID": "blog/project1/hw1_questions (4).html#simulation-experiment",
    "href": "blog/project1/hw1_questions (4).html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nWe simulate two large samples: - One from the control group (donation probability = 0.018) - One from the treatment group (donation probability = 0.022)\nWe calculate the difference between matched pairs, and then compute the cumulative average difference.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate Bernoulli draws\ncontrol_draws = np.random.binomial(1, 0.018, 100_000)\ntreat_draws = np.random.binomial(1, 0.022, 100_000)\n\n# Compute differences and cumulative average\ndiffs = treat_draws - control_draws\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cum_avg, label=\"Cumulative Avg. Difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label=\"True Mean Difference (0.004)\")\nplt.title(\"Law of Large Numbers Simulation\")\nplt.xlabel(\"Number of Observations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe simulation demonstrates the Law of Large Numbers, which states that as the number of observations increases, the sample average converges to the population mean.\nIn this plot, the cumulative average difference in donation rates between the treatment (p = 0.022) and control (p = 0.018) groups begins with wide fluctuations due to randomness in the early observations. However, as we simulate more and more matched pairs (up to 100,000), the cumulative difference stabilizes and converges to the true expected difference of 0.004.\nThis reinforces a key idea in statistics: with large enough sample sizes, the law of averages ensures reliable estimates of population parameters. It also explains why Karlan and List were able to detect small treatment effects — because their experiment had tens of thousands of observations.\n\n\n\n\n### Central Limit Theorem\n\n\nWe simulate distributions of average differences in donation rates between control (p = 0.018) and treatment (p = 0.022) groups, using increasing sample sizes (n = 50, 200, 500, 1000). For each sample size, we repeat the process 1000 times and visualize the distribution of sample differences.\n\n::: {#4931180a .cell execution_count=17}\n``` {.python .cell-code}\ndef run_clt_sim(n, sims=1000, p_control=0.018, p_treat=0.022):\n    diffs = []\n    for _ in range(sims):\n        c = np.random.binomial(1, p_control, n)\n        t = np.random.binomial(1, p_treat, n)\n        diffs.append(np.mean(t) - np.mean(c))\n    return diffs\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\nfor ax, n in zip(axes.flat, sample_sizes):\n    dist = run_clt_sim(n)\n    ax.hist(dist, bins=30, edgecolor='black')\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.axvline(0, color='red', linestyle='--', label='Zero')\n    ax.axvline(0.004, color='green', linestyle='--', label='True Difference')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n:::\n\n\n\nInterpretation\n\nThese four histograms illustrate the Central Limit Theorem using simulated sample means of donation rate differences between the treatment (p = 0.022) and control (p = 0.018) groups.\nAs the sample size increases: - With n = 50, the distribution is wide and noisy — there’s considerable variation, and the true mean difference (0.004) is not clearly distinguishable from zero. - At n = 200, the distribution begins to resemble a bell curve, and the true difference is more centered. - At n = 500, the histogram tightens noticeably, and zero begins to lie closer to the tail of the distribution. - By n = 1000, the sample mean differences are tightly clustered around 0.004, and zero is clearly no longer at the center — it lies in the tail, suggesting strong evidence against the null of no effect.\nThis simulation confirms that larger samples reduce sampling variability and make it easier to detect small, true differences — exactly what Karlan and List leveraged with their large-scale experiment."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hanhua Zhu",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]